# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15qI6FmlYSo0wehCgXIFD6pAW6CaA3n8r
"""

import streamlit as st
from PIL import Image
import torch
import torch.nn as nn
from torchvision import transforms, models
import os

st.set_page_config(page_title="GeoSentioMap", layout="centered")

# Label mapping
emotion_map = {0: 'peaceful', 1: 'neutral', 2: 'energetic', 3: 'chaotic'}

# Metadata encoding
def encode_meta(location, weather, time_of_day):
    location_map = {'kerala': 0, 'chennai': 1}
    weather_map = {'sunny': 0, 'rainy': 1, 'cloudy': 2}
    time_map = {'morning': 0, 'afternoon': 1, 'evening': 2}
    return torch.tensor([
        location_map.get(location, 0),
        weather_map.get(weather, 0),
        time_map.get(time_of_day, 0)
    ], dtype=torch.float32)

# Image transform
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])

# Load model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
resnet.fc = nn.Identity()

class EmotionNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.cnn = resnet
        self.meta_fc = nn.Sequential(
            nn.Linear(3, 16),
            nn.ReLU()
        )
        self.classifier = nn.Sequential(
            nn.Linear(512 + 16, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 4)
        )

    def forward(self, img, meta):
        img_feat = self.cnn(img)
        meta_feat = self.meta_fc(meta)
        combined = torch.cat([img_feat, meta_feat], dim=1)
        return self.classifier(combined)

model = EmotionNet().to(device)
model.load_state_dict(torch.load("emotion_model_final.pt", map_location=device))
model.eval()

# App UI
st.title("üß† GeoSentioMap: Emotion Classifier")

uploaded_file = st.file_uploader("Upload an image", type=["jpg", "png", "jpeg"])

location = st.selectbox("Select Location", ["kerala", "chennai"])
weather = st.selectbox("Select Weather", ["sunny", "rainy", "cloudy"])
time_of_day = st.selectbox("Select Time of Day", ["morning", "afternoon", "evening"])

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="Uploaded Image", use_container_width=True)

    if st.button("üîç Predict Emotion"):
        img_tensor = transform(image).unsqueeze(0).to(device)
        meta_tensor = encode_meta(location, weather, time_of_day).unsqueeze(0).to(device)

        with torch.no_grad():
            output = model(img_tensor, meta_tensor)
            pred = torch.argmax(output, dim=1).item()
            label = emotion_map[pred]

        st.success(f"üéØ Predicted Emotion: **{label.upper()}**")